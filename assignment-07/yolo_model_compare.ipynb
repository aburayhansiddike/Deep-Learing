{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fb6d74c",
   "metadata": {},
   "source": [
    "### Import necessary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed69d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, cv2, torch, numpy as np, pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # headless-safe\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6866b45",
   "metadata": {},
   "source": [
    "### Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae5a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_VIDEO = r\"D:\\sangita-mam\\assignment-07\\rayhan_video.mp4\"\n",
    "OUTPUT_DIR = \"outputs\"; os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3688b86f",
   "metadata": {},
   "source": [
    "### Provide local paths or model names resolvable by Ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0332c3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_WEIGHTS = {\n",
    "    \"yolov8n\": \"yolov8n.pt\",\n",
    "    \"yolo11n\": \"yolo11n.pt\",\n",
    "    \"yolo12n\": \"yolo12n.pt\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6437f6b1",
   "metadata": {},
   "source": [
    "### Configuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c1170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONF_THRESH = 0.25\n",
    "IOU_THRESH  = 0.45\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6955312b",
   "metadata": {},
   "source": [
    "### Ploting setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c337b193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nicer defaults\n",
    "plt.rcParams.update({\n",
    "    \"figure.dpi\": 140,\n",
    "    \"savefig.dpi\": 240,\n",
    "    \"font.size\": 10.5,\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.linestyle\": \"--\",\n",
    "    \"grid.linewidth\": 0.5,\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.spines.right\": False,\n",
    "})\n",
    "\n",
    "def _fmt_val(v):\n",
    "    \"\"\"Pretty number for labels: int if close to int, else 2 decimals.\"\"\"\n",
    "    if isinstance(v, (np.floating, float)):\n",
    "        if np.isfinite(v) and abs(v - round(v)) < 1e-9:\n",
    "            return f\"{int(round(v))}\"\n",
    "        return f\"{v:.2f}\"\n",
    "    if isinstance(v, (np.integer, int)):\n",
    "        return str(int(v))\n",
    "    # fallback\n",
    "    try:\n",
    "        fv = float(v)\n",
    "        if abs(fv - round(fv)) < 1e-9: return f\"{int(round(fv))}\"\n",
    "        return f\"{fv:.2f}\"\n",
    "    except Exception:\n",
    "        return str(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6131dc9",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4661efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(weight_path):\n",
    "    m = YOLO(weight_path)\n",
    "    try:\n",
    "        m.to(DEVICE)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return m\n",
    "\n",
    "def safe_writer(out_stem, fps, size):\n",
    "    \"\"\"Prefer AVI+XVID on Windows; fall back to MP4V if XVID fails.\"\"\"\n",
    "    fps = float(fps if fps and fps > 0 else 30.0)\n",
    "    W, H = size\n",
    "    # Try XVID AVI first\n",
    "    avi_path = os.path.join(OUTPUT_DIR, f\"{out_stem}.avi\")\n",
    "    w = cv2.VideoWriter(avi_path, cv2.VideoWriter_fourcc(*\"XVID\"), fps, (W, H))\n",
    "    if w.isOpened():\n",
    "        return w, avi_path\n",
    "    # Fallback MP4V\n",
    "    mp4_path = os.path.join(OUTPUT_DIR, f\"{out_stem}.mp4\")\n",
    "    w2 = cv2.VideoWriter(mp4_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (W, H))\n",
    "    if w2.isOpened():\n",
    "        return w2, mp4_path\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48e7add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(frame, boxes, confs, clss, names):\n",
    "    img = frame.copy()\n",
    "    for (x1,y1,x2,y2), c, ci in zip(boxes, confs, clss):\n",
    "        x1,y1,x2,y2 = map(int, [x1,y1,x2,y2])\n",
    "        label = f\"{names[int(ci)]} {c:.2f}\"\n",
    "        cv2.rectangle(img, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "        (tw, th), _ = cv2.getTextSize(label, FONT, 0.5, 1)\n",
    "        cv2.rectangle(img, (x1, y1-th-6), (x1+tw+4, y1), (0,255,0), -1)\n",
    "        cv2.putText(img, label, (x1+2, y1-4), FONT, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "def predict_on_frame(model, frame):\n",
    "    res = model.predict(source=frame, conf=CONF_THRESH, iou=IOU_THRESH, verbose=False, device=DEVICE)[0]\n",
    "    if res.boxes is None or len(res.boxes) == 0:\n",
    "        return np.empty((0,4)), np.array([]), np.array([], dtype=int)\n",
    "    boxes = res.boxes.xyxy.detach().cpu().numpy()\n",
    "    confs = res.boxes.conf.detach().cpu().numpy()\n",
    "    clss  = res.boxes.cls.detach().cpu().numpy().astype(int)\n",
    "    return boxes, confs, clss\n",
    "\n",
    "def robust_read_frame(video_path, target_idx):\n",
    "    \"\"\"Decode sequentially to target_idx (more reliable than CAP_PROP_POS_FRAMES).\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return None\n",
    "    idx, frame = 0, None\n",
    "    while idx <= target_idx:\n",
    "        ok, f = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        frame = f\n",
    "        idx += 1\n",
    "    cap.release()\n",
    "    return frame if frame is not None and idx-1 == target_idx else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a483b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_common_idx_with_v8(video_path, v8_model):\n",
    "    \"\"\"Pick the frame index with the most detections using v8.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise FileNotFoundError(video_path)\n",
    "    best_idx, best_cnt, idx = 0, -1, 0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        boxes, confs, clss = predict_on_frame(v8_model, frame)\n",
    "        if len(confs) > best_cnt:\n",
    "            best_cnt, best_idx = len(confs), idx\n",
    "        idx += 1\n",
    "    cap.release()\n",
    "    # fallback to middle if no frames\n",
    "    if best_cnt < 0:\n",
    "        best_idx = max(0, idx // 2)\n",
    "    return best_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_full_video(model_name, weight, input_path, common_idx):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        raise FileNotFoundError(input_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    W   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) or 1280)\n",
    "    H   = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) or 720)\n",
    "\n",
    "    writer, out_path = safe_writer(f\"{model_name}_annotated\", fps, (W,H))\n",
    "    if writer is None:\n",
    "        cap.release()\n",
    "        raise RuntimeError(f\"Failed to open writer for {model_name}\")\n",
    "\n",
    "    model = load_model(weight)\n",
    "    names = model.model.names if hasattr(model.model, \"names\") else model.names\n",
    "\n",
    "    frames, tot_det, t_sum = 0, 0, 0.0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        t0 = time.time()\n",
    "        boxes, confs, clss = predict_on_frame(model, frame)\n",
    "        t_sum += (time.time() - t0)\n",
    "        tot_det += len(confs); frames += 1\n",
    "        writer.write(annotate(frame, boxes, confs, clss, names))\n",
    "    cap.release(); writer.release()\n",
    "\n",
    "    # ensure at least one frame written, else mark as failed\n",
    "    if frames == 0:\n",
    "        try: os.remove(out_path)\n",
    "        except: pass\n",
    "        raise RuntimeError(f\"No frames processed for {model_name}; output removed\")\n",
    "\n",
    "    # SAME snapshot for ALL models\n",
    "    snap = robust_read_frame(input_path, common_idx)\n",
    "    if snap is None:\n",
    "        raise RuntimeError(f\"Failed to read comparison frame idx={common_idx}\")\n",
    "    s_boxes, s_confs, s_clss = predict_on_frame(model, snap)\n",
    "    snap_anno = annotate(snap, s_boxes, s_confs, s_clss, names)\n",
    "    snap_path = os.path.join(OUTPUT_DIR, f\"{model_name}_selected_frame_sameidx_{common_idx}.jpg\")\n",
    "    cv2.imwrite(snap_path, snap_anno)\n",
    "\n",
    "    fps_eff = frames / t_sum if t_sum > 0 else 0.0\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"output_video\": out_path,\n",
    "        \"frames_processed\": frames,\n",
    "        \"throughput_fps\": fps_eff,\n",
    "        \"total_detections\": tot_det,\n",
    "        \"avg_detections_per_frame\": tot_det / max(frames, 1),\n",
    "        \"selected_frame_index\": common_idx,\n",
    "        \"selected_frame_det_count\": int(len(s_confs)),\n",
    "        \"selected_frame_path\": snap_path,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10f5b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- PLOTTING -------------------------\n",
    "def _label_bars(ax, bars, values, pad=0.01):\n",
    "    \"\"\"Add value labels on top of bars with smart formatting.\"\"\"\n",
    "    y_max = max(values) if len(values) else 1.0\n",
    "    for rect, v in zip(bars, values):\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(_fmt_val(v),\n",
    "                    xy=(rect.get_x() + rect.get_width()/2, height),\n",
    "                    xytext=(0, 5), textcoords=\"offset points\",\n",
    "                    ha=\"center\", va=\"bottom\", fontsize=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df72c6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_bar(df, col, ylabel, title, filename):\n",
    "    vals = df[col].values\n",
    "    labels = df[\"model\"].values\n",
    "    xs = np.arange(len(vals))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8.8, 4.8))\n",
    "    bars = ax.bar(xs, vals)\n",
    "    ax.set_xticks(xs, labels)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    _label_bars(ax, bars, vals)\n",
    "    fig.tight_layout()\n",
    "    outp = os.path.join(OUTPUT_DIR, filename)\n",
    "    fig.savefig(outp, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {outp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9737141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_scatter_fps_vs_avgdet(df, filename):\n",
    "    x = df[\"throughput_fps\"].values\n",
    "    y = df[\"avg_detections_per_frame\"].values\n",
    "    labels = df[\"model\"].values\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.2, 5.4))\n",
    "    ax.scatter(x, y, s=90)\n",
    "    for xi, yi, lab in zip(x, y, labels):\n",
    "        ax.annotate(lab, (xi, yi), textcoords=\"offset points\", xytext=(6, 6), fontsize=9)\n",
    "    ax.set_xlabel(\"Throughput (FPS)\")\n",
    "    ax.set_ylabel(\"Avg detections per frame\")\n",
    "    ax.set_title(\"Speed vs Density (higher-right is better)\")\n",
    "    ax.grid(True, linestyle=\"--\", linewidth=0.6)\n",
    "    fig.tight_layout()\n",
    "    outp = os.path.join(OUTPUT_DIR, filename)\n",
    "    fig.savefig(outp, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {outp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2357da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_grouped_fps_avgdet(df, filename):\n",
    "    labels = df[\"model\"].values\n",
    "    fps = df[\"throughput_fps\"].values\n",
    "    avgd = df[\"avg_detections_per_frame\"].values\n",
    "\n",
    "    xs = np.arange(len(labels))\n",
    "    width = 0.38\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9.2, 5.0))\n",
    "    b1 = ax.bar(xs - width/2, fps,  width, label=\"FPS\")\n",
    "    b2 = ax.bar(xs + width/2, avgd, width, label=\"Avg det./frame\")\n",
    "    ax.set_xticks(xs, labels)\n",
    "    ax.set_ylabel(\"Value\")\n",
    "    ax.set_title(\"Grouped Comparison: FPS vs Avg detections\")\n",
    "    ax.legend()\n",
    "    _label_bars(ax, b1, fps)\n",
    "    _label_bars(ax, b2, avgd)\n",
    "    fig.tight_layout()\n",
    "    outp = os.path.join(OUTPUT_DIR, filename)\n",
    "    fig.savefig(outp, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {outp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e9608e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Common frame] index = 103\n",
      "\n",
      "--- Running yolov8n ---\n",
      "OK: outputs\\yolov8n_annotated.avi\n",
      "Snapshot: outputs\\yolov8n_selected_frame_sameidx_103.jpg (idx=103, det=8)\n",
      "FPS=59.95, total=2050, avg/frame=6.21\n",
      "\n",
      "--- Running yolo11n ---\n",
      "OK: outputs\\yolo11n_annotated.avi\n",
      "Snapshot: outputs\\yolo11n_selected_frame_sameidx_103.jpg (idx=103, det=8)\n",
      "FPS=57.31, total=2665, avg/frame=8.08\n",
      "\n",
      "--- Running yolo12n ---\n",
      "OK: outputs\\yolo12n_annotated.avi\n",
      "Snapshot: outputs\\yolo12n_selected_frame_sameidx_103.jpg (idx=103, det=9)\n",
      "FPS=46.16, total=2942, avg/frame=8.92\n",
      "\n",
      "Saved table: outputs\\comparison_table.csv\n",
      "\n",
      "Comparison:\n",
      "  model  throughput_fps  total_detections  avg_detections_per_frame  selected_frame_index  selected_frame_det_count                            selected_frame_path\n",
      "yolov8n           59.95              2050                      6.21                   103                         8 outputs\\yolov8n_selected_frame_sameidx_103.jpg\n",
      "yolo11n           57.31              2665                      8.08                   103                         8 outputs\\yolo11n_selected_frame_sameidx_103.jpg\n",
      "yolo12n           46.16              2942                      8.92                   103                         9 outputs\\yolo12n_selected_frame_sameidx_103.jpg\n",
      "Saved: outputs\\chart_throughput_fps.png\n",
      "Saved: outputs\\chart_total_detections.png\n",
      "Saved: outputs\\chart_avg_detections_per_frame.png\n",
      "Saved: outputs\\chart_shared_frame_detections.png\n",
      "Saved: outputs\\chart_fps_vs_avgdet_scatter.png\n",
      "Saved: outputs\\chart_grouped_fps_avgdet.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------- MAIN -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(INPUT_VIDEO):\n",
    "        raise FileNotFoundError(f\"Missing: {INPUT_VIDEO}\")\n",
    "\n",
    "    # 1) pick ONE common frame with YOLOv8\n",
    "    v8 = load_model(MODEL_WEIGHTS[\"yolov8n\"])\n",
    "    common_idx = choose_common_idx_with_v8(INPUT_VIDEO, v8)\n",
    "    print(f\"[Common frame] index = {common_idx}\")\n",
    "\n",
    "    # 2) run all models, force SAME snapshot\n",
    "    summaries = []\n",
    "    for name, weight in MODEL_WEIGHTS.items():\n",
    "        print(f\"\\n--- Running {name} ---\")\n",
    "        try:\n",
    "            s = run_model_full_video(name, weight, INPUT_VIDEO, common_idx)\n",
    "            summaries.append(s)\n",
    "            print(f\"OK: {s['output_video']}\")\n",
    "            print(f\"Snapshot: {s['selected_frame_path']} (idx={common_idx}, det={s['selected_frame_det_count']})\")\n",
    "            print(f\"FPS={s['throughput_fps']:.2f}, total={s['total_detections']}, avg/frame={s['avg_detections_per_frame']:.2f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] {name} failed: {e}\")\n",
    "\n",
    "    if summaries:\n",
    "        df = pd.DataFrame(summaries)\n",
    "        csv_path = os.path.join(OUTPUT_DIR, \"comparison_table.csv\")\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(\"\\nSaved table:\", csv_path)\n",
    "\n",
    "        # Console view (rounded for readability)\n",
    "        df_view = df.copy()\n",
    "        df_view[\"throughput_fps\"] = df_view[\"throughput_fps\"].map(lambda v: float(f\"{v:.2f}\"))\n",
    "        df_view[\"avg_detections_per_frame\"] = df_view[\"avg_detections_per_frame\"].map(lambda v: float(f\"{v:.2f}\"))\n",
    "        print(\"\\nComparison:\")\n",
    "        print(df_view[[\n",
    "            \"model\",\"throughput_fps\",\"total_detections\",\"avg_detections_per_frame\",\n",
    "            \"selected_frame_index\",\"selected_frame_det_count\",\"selected_frame_path\"\n",
    "        ]].to_string(index=False))\n",
    "\n",
    "        # --------- Pretty Charts ---------\n",
    "        save_bar(df, \"throughput_fps\", \"FPS\", \"Model Throughput (FPS)\", \"chart_throughput_fps.png\")\n",
    "        save_bar(df, \"total_detections\", \"Count\", \"Total Detections (whole video)\", \"chart_total_detections.png\")\n",
    "        save_bar(df, \"avg_detections_per_frame\", \"Avg / frame\", \"Average Detections per Frame\", \"chart_avg_detections_per_frame.png\")\n",
    "        save_bar(\n",
    "            df, \"selected_frame_det_count\", \"Count\",\n",
    "            f\"Detections on Shared Frame (idx={int(df['selected_frame_index'].iloc[0])})\",\n",
    "            \"chart_shared_frame_detections.png\"\n",
    "        )\n",
    "        save_scatter_fps_vs_avgdet(df, \"chart_fps_vs_avgdet_scatter.png\")\n",
    "        save_grouped_fps_avgdet(df, \"chart_grouped_fps_avgdet.png\")\n",
    "\n",
    "    else:\n",
    "        print(\"No successful runs.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
